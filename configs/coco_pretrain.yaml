DATA:
  data_name: coco
  split: 0
  data_root: /coco/
  train_list: lists/coco/train.txt
  val_list: lists/coco/val.txt
  num_classes_tr: 61    # Counting background for training
  num_classes_val: 20
  use_split_coco: True
  workers: 2
  image_size: 473
  padding_label: 255
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  scale_min: 0.5
  scale_max: 2.0
  rot_min: -10
  rot_max: 10
  augmentations: ['hor_flip', 'vert_flip', 'resize']

TRAIN:
  ckpt_path: checkpoints/
  batch_size: 8
  epochs: 20
  log_freq: 100
  save_models: True
  lr: 0.0025
  cls_lr: 0.05
  scale_lr: 2.0
  mixup: False
  lr_stepsize: 30       # LR scheduler
  momentum: 0.9
  gamma: 0.1            # LR scheduler
  nesterov: True
  weight_decay: 0.0001
  main_optim: SGD
  scheduler: cosine
  milestones: [40, 70]

MODEL:
  arch: resnet
  pretrained: True  # Means the backbone has been pre-trained
  bins: [1, 2, 3, 6]
  dropout: 0.1
  m_scale: False
  layers: 50
  bottleneck_dim: 512
  feature_res: [60, 60]


EVALUATION:
  episodic_val: False
  shot: 1
  random_shot: False
  norm_feat: True           # ?
  batch_size_val: 100     # not used
  manual_seed: 42
  ckpt_used: best
  test_num: 1000
  FB_param_noise: 0
  smoothing: True
  n_runs: 2

CLASSIFIER:
  adapt_iter: 200

EXPERIMENT:
  exp_name: pretrain_dot

DISTRIBUTED:
  gpus: [0]
